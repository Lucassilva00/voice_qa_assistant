{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "7fwJimHnvzoo",
        "FX8-XR-eyZ1K",
        "QgrBWnkiBn9S"
      ],
      "authorship_tag": "ABX9TyO9AbqzHVDXtRZkuMcEA5Tc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lucassilva00/voice_qa_assistant/blob/main/notebooks/voice_qa_assistant.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9pmdmmpuPjj"
      },
      "outputs": [],
      "source": [
        "#Define a linguagem a ser usada pelo whisper e gTTS\n",
        "language = 'pt'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Gravação de Áudio Com Python"
      ],
      "metadata": {
        "id": "7fwJimHnvzoo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio, display, Javascript\n",
        "from google.colab import output\n",
        "from base64 import b64decode\n",
        "\n",
        "RECORD = \"\"\"\n",
        "const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n",
        "const b2text = blob => new Promise(resolve => {\n",
        "  const reader = new FileReader()\n",
        "  reader.onloadend = e => resolve(e.srcElement.result)\n",
        "  reader.readAsDataURL(blob)\n",
        "})\n",
        "var record = time => new Promise(async resolve => {\n",
        "  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
        "  recorder = new MediaRecorder(stream)\n",
        "  chunks = []\n",
        "  recorder.ondataavailable = e => chunks.push(e.data)\n",
        "  recorder.start()\n",
        "  await sleep(time)\n",
        "  recorder.onstop = async ()=>{\n",
        "    blob = new Blob(chunks)\n",
        "    text = await b2text(blob)\n",
        "    resolve(text)\n",
        "  }\n",
        "  recorder.stop()\n",
        "})\n",
        "\"\"\"\n",
        "\n",
        "def record(sec=5):\n",
        "  display(Javascript(RECORD))\n",
        "\n",
        "  js_result = output.eval_js('record(%s)' % (sec * 1000))\n",
        "\n",
        "  audio = b64decode(js_result.split(',')[1])\n",
        "\n",
        "  #Salva o áudio\n",
        "  file_name = 'request_audio.wav'\n",
        "  with open(file_name, 'wb') as f:\n",
        "    f.write(audio)\n",
        "\n",
        "  return f'/content/{file_name}'\n",
        "\n",
        "print('Gravando...\\n')\n",
        "record_file = record()\n",
        "\n",
        "display(Audio(record_file, autoplay = False))\n"
      ],
      "metadata": {
        "id": "KAAlXRhXv1HW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Reconhecimento de Fala com Whisper"
      ],
      "metadata": {
        "id": "qmTIR5qB0coz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/whisper.git -q"
      ],
      "metadata": {
        "collapsed": true,
        "id": "smHsx7iY0gX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "#Escolha do modelo\n",
        "model = whisper.load_model(\"small\")\n",
        "\n",
        "#Transcreve o áudio e mostra o resultado\n",
        "result = model.transcribe(record_file, fp16=False, language=language)\n",
        "transcription = result[\"text\"]\n",
        "print(transcription)"
      ],
      "metadata": {
        "id": "y9rt1S0TimE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Integração com a API do Google Gemini\n"
      ],
      "metadata": {
        "id": "FX8-XR-eyZ1K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U google-genai"
      ],
      "metadata": {
        "collapsed": true,
        "id": "QwbjHfVPycic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.colab import userdata\n",
        "\n",
        "#Na aba secret cria-se uma chave secreta e substitua secretName pelo nome de sua chave\n",
        "import os\n",
        "os.environ[\"GEMINI_API_KEY\"] = userdata.get(\"secretName\")\n",
        "\n",
        "client = genai.Client()\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    contents=transcription\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "A1ZJgmXnzZ3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Sintetizando a Resposta do Gemini com Voz (gTTS)"
      ],
      "metadata": {
        "id": "QgrBWnkiBn9S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gTTS"
      ],
      "metadata": {
        "collapsed": true,
        "id": "FUmqwz1qBq4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gtts import gTTS\n",
        "\n",
        "gtts_object = gTTS(text=response.text, lang=language, slow=False)\n",
        "\n",
        "response_audio = \"/content/response_audio.mp3\"\n",
        "gtts_object.save(response_audio)\n",
        "\n",
        "display(Audio(response_audio, autoplay=False))"
      ],
      "metadata": {
        "id": "BEO4WH3NBugy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}